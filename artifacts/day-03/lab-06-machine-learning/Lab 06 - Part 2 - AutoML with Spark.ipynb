{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "description": null,
    "save_output": false,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Analyze and prepare the customer ratings dataset\r\n",
        "\r\n",
        "Use `spark.read.csv()` to load the data from the source public blob storage account and display its schema and shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "url = \"wasbs://files@synapsemlpublic.blob.core.windows.net/PersonalizedData.csv\"\r\n",
        "raw_data = spark.read.csv(url, header=True, inferSchema=True)\r\n",
        "print(\"Schema: \")\r\n",
        "raw_data.printSchema()\r\n",
        "\r\n",
        "df = raw_data.toPandas()\r\n",
        "print(\"Shape: \", df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Take a look at some of the items in the dataset. Notice the two-class ratings (0 vs. 1) provided by customers to products.\r\n",
        "\r\n",
        "The goal of this exercise is to build a Machine Learning classification model capable of predicting the rating based on Cost, Size, Price, PrimaryBrandId, GenderId, MaritalStatus, LowerIncomeBound, and UpperIncomeBound. To achieve the goal, you will use Azure Machine Learning (AML) automated machine learning (Auto ML)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "source": [
        "display(df.iloc[:10, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Split the data into the train and test parts using a ratio of 80% train to 20% test.\r\n",
        "\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "split_ratio = 0.8\n",
        "seed = 42\n",
        "raw_train, raw_test = raw_data.randomSplit([split_ratio, 1 - split_ratio], seed=seed)\n",
        "print(\"Train: (rows, columns) = {}\".format((raw_train.count(), len(raw_train.columns))))\n",
        "print(\"Test: (rows, columns) = {}\".format((raw_test.count(), len(raw_test.columns))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Use the subscription id, resource group name, AML workspace name, and AML workspace region from your environment to connect to the AML workspace. Make sure the values are identical to the ones displayed in the Azure portal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "# Enter your workspace subscription, resource group, name, and region.\r\n",
        "subscription_id = \"153b2544-398a-45ea-a683-b41ddd681d56\" #you should be owner or contributor\r\n",
        "resource_group = \"Synapse-WS-L400-524101\" #you should be owner or contributor\r\n",
        "workspace_name = \"amlworkspace524101\" #your workspace name\r\n",
        "workspace_region = \"northeurope\" #your region\r\n",
        "\r\n",
        "ws = Workspace(workspace_name = workspace_name,\r\n",
        "               subscription_id = subscription_id,\r\n",
        "               resource_group = resource_group)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Persist the train and test datasets as CSV files and upload them to the AML data store.\r\n",
        "\r\n",
        "Load the train dataset as an AML tabular dataset (this format is used by the AutoML run)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "import pandas \r\n",
        "from azureml.core import Dataset\r\n",
        "\r\n",
        "# Get the Azure Machine Learning default datastore\r\n",
        "datastore = ws.get_default_datastore()\r\n",
        "\r\n",
        "train_pd = raw_train.toPandas()\r\n",
        "train_pd[train_pd.columns[2:]].to_csv('train.csv', index=False)\r\n",
        "test_pd = raw_test.toPandas()\r\n",
        "test_pd[test_pd.columns[2:]].to_csv('test.csv', index=False)\r\n",
        "\r\n",
        "# Convert into an Azure Machine Learning tabular dataset\r\n",
        "datastore.upload_files(files = ['train.csv', 'test.csv'],\r\n",
        "                       target_path = 'train-dataset/tabular/',\r\n",
        "                       overwrite = True,\r\n",
        "                       show_progress = True)\r\n",
        "ds_train = Dataset.Tabular.from_delimited_files(path = [(datastore, 'train-dataset/tabular/train.csv')])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Use AML Auto ML to train the classification model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Configure the AutoML run to use at most 20 iterations (combinations of ML algorithms and hyper-parameter values). This limitation will ensure the AutoML run will not exceed a total run time of 7-8 minutes.\r\n",
        "\r\n",
        "The `enable_onnx_compatible_models` ensures the run produces a model that is ONNX compatible. This will make the model available for inference directly on dedicated SQL pool tables, via the AML linked service configured in Synapse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "import logging\r\n",
        "\r\n",
        "automl_settings = {\r\n",
        "    \"iterations\": 20,\r\n",
        "    \"iteration_timeout_minutes\": 5,\r\n",
        "    \"experiment_timeout_minutes\": 15,\r\n",
        "    \"max_concurrent_iterations\": 2,\r\n",
        "    \"enable_early_stopping\": True,\r\n",
        "    \"enable_onnx_compatible_models\": True,\r\n",
        "    \"primary_metric\": 'accuracy',\r\n",
        "    \"featurization\": 'auto',\r\n",
        "    \"verbosity\": logging.INFO,\r\n",
        "    \"n_cross_validations\": 2}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Finalize the configuration of the AutoML run. Specify the task type (`classification`), the data to train on, and the compute resource to use. In this case, `spark_context = sc` specifies that the AutoML run will use the local Spark pool as the compute resource to run the entire process. \r\n",
        "The AML workspace is still coordinating the whole process, but the compute being used is local."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from azureml.train.automl import AutoMLConfig\r\n",
        "\r\n",
        "automl_config = AutoMLConfig(task='classification',\r\n",
        "                             debug_log='automated_ml_errors.log',\r\n",
        "                             training_data = ds_train,\r\n",
        "                             spark_context = sc,\r\n",
        "                             model_explainability = True, \r\n",
        "                             label_column_name =\"Rating\",**automl_settings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Submit the AutoML run and wait for its completion. The settings were chosen in a way that the total run time should not exceed 7-8 minutes. While the experiment is running, go ahead and open the Azure Machine Learning Studio in the Azure portal and check out the details of the AutoML run.\r\n",
        "\r\n",
        "Once the run completes, check the list of trained models and their performance metric (`accuracy` in our case)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from azureml.core.experiment import Experiment\r\n",
        "\r\n",
        "# Start an experiment in Azure Machine Learning\r\n",
        "experiment = Experiment(ws, \"aml-synapse-classification\")\r\n",
        "tags = {\"Synapse\": \"classification\"}\r\n",
        "local_run = experiment.submit(automl_config, tags = tags)\r\n",
        "local_run.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Register the best model in the AML workspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Retrieve the best model and its associated child run from the AutoML run. Inspect the properties of the child run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Get best model\r\n",
        "best_run, fitted_model = local_run.get_output()\r\n",
        "best_run.properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "description = 'Classification model trained by AutoML running on Synapse Spark'\r\n",
        "model_path='outputs/model.onnx'\r\n",
        "model = best_run.register_model(model_name = 'aml-synapse-classifier', model_path = model_path, description = description, model_framework='ONNX')\r\n",
        "print(model.name, model.version)"
      ]
    }
  ]
}